{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e62eeb",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cd47b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating train split: 100%|██████████| 26732/26732 [00:00<00:00, 302255.92 examples/s]\n",
      "Generating test split: 100%|██████████| 3432/3432 [00:00<00:00, 487696.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_df = load_dataset(\"mteb/tweet_sentiment_extraction\")['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "afa26c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>726e501993</td>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  label  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh      1   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...      2   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...      0   \n",
       "3  33987a8ee5             http://twitpic.com/4w75p - I like it!!      2   \n",
       "4  726e501993                    that`s great!! weee!! visitors!      2   \n",
       "\n",
       "  label_text  \n",
       "0    neutral  \n",
       "1   positive  \n",
       "2   negative  \n",
       "3   positive  \n",
       "4   positive  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "97fd2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.label = test_df.label_text.map({'negative': 2, 'neutral': 1, 'positive': 0}) # Map labels to match our convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "09b68544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    0.400641\n",
       "0    0.312937\n",
       "2    0.286422\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "64b6f79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.text.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dbf36d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "text          0\n",
       "label         0\n",
       "label_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7045b7c",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9298caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import numpy as np\n",
    "CONTRACTION_PATH = '../data/mapping/contraction.csv'\n",
    "EMOJI_PATH = '../data/mapping/emoji.csv'\n",
    "\n",
    "# === Contraction ===\n",
    "contraction_df = pd.read_csv(CONTRACTION_PATH, encoding='utf-8')\n",
    "contraction_map = {key: value for key, value in zip(contraction_df.contraction, contraction_df.extension)}\n",
    "\n",
    "contraction_pattern = re.compile(\n",
    "    r\"\\b(\" + \"|\".join(map(re.escape, contraction_map.keys())) + r\")\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "def replace_contraction(match):\n",
    "    w = match.group(0).lower()\n",
    "    if w in contraction_map:\n",
    "        return contraction_map[match.group(0).lower()]\n",
    "    else:\n",
    "        return w\n",
    "\n",
    "def extend(text):\n",
    "    return re.sub(contraction_pattern, replace_contraction, text)\n",
    "\n",
    "\n",
    "\n",
    "# === Emoji ===\n",
    "emoji_df = pd.read_csv(EMOJI_PATH, encoding='utf-8')\n",
    "emoji_df['Score'] = np.tanh(\n",
    "    np.log((emoji_df.Positive + 1) / (emoji_df.Negative + 1))\n",
    ")\n",
    "\n",
    "GENDER_EMOJI_MAP = {\n",
    "    \"\\u2640\": \"[EMO_FEMALE]\",  # ♀\n",
    "    \"\\u2642\": \"[EMO_MALE]\",    # ♂\n",
    "    \"\\u26A7\": \"[EMO_TRANS]\"    # ⚧\n",
    "}\n",
    "\n",
    "def normalize_emoji(e):\n",
    "    e = re.sub(r\"\\uFE0F\", \"\", e)\n",
    "    if e in GENDER_EMOJI_MAP:\n",
    "        return GENDER_EMOJI_MAP[e]\n",
    "    e = re.sub(r\"\\u200d\", \"\", e)\n",
    "    return e\n",
    "\n",
    "emoji_df['Emoji_norm'] = emoji_df['Emoji'].apply(normalize_emoji)\n",
    "emoji_df = emoji_df[emoji_df['Emoji_norm'].str.len() > 0]\n",
    "\n",
    "emoji_list = sorted(\n",
    "    emoji_df['Emoji_norm'].unique(),\n",
    "    key=len,\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "emoji_map = dict(\n",
    "    zip(\n",
    "        emoji_df['Emoji_norm'],\n",
    "        zip(emoji_df['Unicode name'], emoji_df.Score)\n",
    "    )\n",
    ")\n",
    "\n",
    "def extract_emoji(sentence, beta=1.0):\n",
    "    emoji_scores = []\n",
    "    new_text = sentence\n",
    "    strongest = 0.0\n",
    "\n",
    "    for e in emoji.emoji_list(sentence):\n",
    "        em = e['emoji']\n",
    "        norm_em = normalize_emoji(em)\n",
    "\n",
    "        if not norm_em.startswith(\"[EMO_\"):\n",
    "            name, score = emoji_map.get(norm_em, ('[EMO]', 0.0))\n",
    "            if score != 0.0:\n",
    "                emoji_scores.append(score)\n",
    "        else:\n",
    "            name = norm_em\n",
    "\n",
    "        new_text = new_text.replace(em, name)\n",
    "\n",
    "    if emoji_scores:\n",
    "        strongest = max(emoji_scores, key=lambda s: abs(s))\n",
    "\n",
    "    return new_text, strongest * beta\n",
    "\n",
    "\n",
    "\n",
    "# === Markdown reddit ===\n",
    "def extract_markdown(text):\n",
    "    # spoiler\n",
    "    text = re.sub(r\">!(.+?)!<\", r\" <spoiler> \\1 </spoiler> \", text)\n",
    "\n",
    "    # bold + italic\n",
    "    text = re.sub(r\"\\*\\*\\*(.+?)\\*\\*\\*\", r\" <bi> \\1 </bi> \", text)\n",
    "\n",
    "    # bold\n",
    "    text = re.sub(r\"\\*\\*(.+?)\\*\\*\", r\" <b> \\1 </b> \", text)\n",
    "\n",
    "    # italic *\n",
    "    text = re.sub(r\"\\*(?!\\*)(.+?)(?<!\\*)\\*\", r\" <i> \\1 </i> \", text)\n",
    "\n",
    "    # strike\n",
    "    text = re.sub(r\"~~(.+?)~~\", r\" <s> \\1 </s> \", text)\n",
    "\n",
    "    # quote (line-based)\n",
    "    text = re.sub(r\"^>(.+)\", r\" <q> \\1 </q> \", text, flags=re.M)\n",
    "\n",
    "    # inline code\n",
    "    text = re.sub(r\"`(.+?)`\", r\" <code> \\1 </code> \", text)\n",
    "\n",
    "    # triple double quotes\n",
    "    text = re.sub(r'\"\"\"\\s*(.+?)\\s*\"\"\"', r' <quote> \\1 </quote> ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# === Mention ===\n",
    "def normalize_mention(text):\n",
    "    return re.sub(r\"(?<!\\w)@[A-Za-z_][A-Za-z0-9_]{1,30}\", '[MENTION]', text)    \n",
    "\n",
    "\n",
    "\n",
    "# === URL ===\n",
    "def normalize_url(text):\n",
    "    return re.sub(r\"https?://\\S+|www\\.\\S+\", '[URL]', text)\n",
    "\n",
    "\n",
    "\n",
    "# === Time ===\n",
    "def normalize_time(text):\n",
    "    return re.sub(r\"\\b(?:1[0-2]|0?[1-9]):[0-5][0-9]\\s*(?i:am|pm)\\b\", '[TIME]', text)\n",
    "\n",
    "\n",
    "\n",
    "# === Date ===\n",
    "def normalize_date(text):\n",
    "    # ISO 8601 datetime: 2026-01-07T10:30:00\n",
    "    text = re.sub(r\"\\b\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\b\", \"[DATE]\", text)\n",
    "    # YYYY-MM-DD\n",
    "    text = re.sub(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\", \"[DATE]\", text)\n",
    "    # MM/DD/YYYY\n",
    "    text = re.sub(r\"\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b\", \"[DATE]\", text)\n",
    "    # DD-MM-YYYY\n",
    "    text = re.sub(r\"\\b\\d{1,2}-\\d{1,2}-\\d{4}\\b\", \"[DATE]\", text)\n",
    "    # Month Day, Year (Jan 7, 2026 or January 7, 2026)\n",
    "    text = re.sub(\n",
    "        r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|\"\n",
    "        r\"January|February|March|April|May|June|July|August|September|October|November|December)\"\n",
    "        r\"\\s+\\d{1,2},\\s*\\d{4}\\b\", \"[DATE]\", text\n",
    "    )\n",
    "    # Day Month Year (7 Jan 2026 or 7 January 2026)\n",
    "    text = re.sub(\n",
    "        r\"\\b\\d{1,2}\\s+\"\n",
    "        r\"(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|\"\n",
    "        r\"January|February|March|April|May|June|July|August|September|October|November|December)\"\n",
    "        r\"\\s+\\d{4}\\b\", \"[DATE]\", text\n",
    "    )\n",
    "    # Compact numeric YYYYMMDD\n",
    "    text = re.sub(r\"\\b\\d{8}\\b\", \"[DATE]\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# === Hashtag ===\n",
    "def normalize_hashtag(text):\n",
    "\n",
    "    def repl(m):\n",
    "        tag = m.group()[1:]\n",
    "        tag = tag.lower()\n",
    "        return f\"[HASHTAG] {tag}\"\n",
    "    \n",
    "    return re.sub(r'#\\w+', repl, text)\n",
    "\n",
    "\n",
    "\n",
    "# === Whitespace ===\n",
    "def normalize_whitespace(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "\n",
    "# === Lowercase ===\n",
    "def lowercase(text):\n",
    "    token_pattern = r'(\\[[A-Z_]+\\])'\n",
    "\n",
    "    parts = re.split(token_pattern, text)\n",
    "\n",
    "    parts = [p.lower() if not re.fullmatch(token_pattern, p) else p for p in parts]\n",
    "\n",
    "    return ''.join(parts)\n",
    "\n",
    "\n",
    "\n",
    "# === Punctuation ===\n",
    "def normalize_punctuation(text: str) -> str:\n",
    "    text = re.sub(r'\\.{3,}', '...', text)\n",
    "\n",
    "    text = re.sub(r'!{3,}', '!!', text)\n",
    "    text = re.sub(r'\\?{3,}', '??', text)\n",
    "\n",
    "    text = re.sub(r'(!\\?|\\?!){2,}', '!?', text)\n",
    "\n",
    "    text = re.sub(r'\\s+([!?.,])', r'\\1', text)\n",
    "    text = re.sub(r'([!?.,])\\s+', r'\\1 ', text)\n",
    "\n",
    "    text = re.sub(r'([,;:]){2,}', r'\\1', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# === All uppercase ===\n",
    "def extract_is_all_uppercase(text):\n",
    "    return text, int(text.isupper())\n",
    "\n",
    "\n",
    "\n",
    "# === Uppercase ratio ===\n",
    "def extract_uppercase_ratio(text):\n",
    "    clean_text = re.sub(r'\\[[A-Z_]+\\]', '', text)\n",
    "    \n",
    "    alphas = [c for c in clean_text if c.isalpha()]\n",
    "    \n",
    "    if not alphas:\n",
    "        return text,0.0\n",
    "    \n",
    "    return text, sum(c.isupper() for c in alphas) / len(alphas)\n",
    "\n",
    "\n",
    "\n",
    "# === Exclaimination ===\n",
    "def extract_exclamation_intensity(text, cap=5):\n",
    "    max_run = 0\n",
    "    cur = 0\n",
    "    for c in text:\n",
    "        if c == '!':\n",
    "            cur += 1\n",
    "            max_run = max(max_run, cur)\n",
    "        else:\n",
    "            cur = 0\n",
    "\n",
    "    return text, min(max_run, cap) / cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331f279",
   "metadata": {},
   "source": [
    "### Pipeline order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a358fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "preprocessing_pipeline = [\n",
    "    (partial(extract_exclamation_intensity, cap=5), 'ex_intensity'),\n",
    "    (extract_markdown),\n",
    "    (extend),\n",
    "    (partial(extract_emoji, beta=1.0), 'emoji_score'),\n",
    "    (normalize_mention),\n",
    "    (normalize_url),\n",
    "    (normalize_time),\n",
    "    (normalize_date),\n",
    "    (normalize_hashtag),\n",
    "    (normalize_whitespace),\n",
    "    (extract_is_all_uppercase, 'all_uppercase'),\n",
    "    (extract_uppercase_ratio, 'uppercase_ratio'),\n",
    "    (lowercase),\n",
    "    (normalize_punctuation)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4c963efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(text):\n",
    "    res = {\"text\": text}\n",
    "\n",
    "    for process in preprocessing_pipeline:\n",
    "\n",
    "        if isinstance(process, tuple):\n",
    "            func, key = process\n",
    "            res['text'], res[key] = func(res['text'])\n",
    "        else:\n",
    "            func = process\n",
    "            res['text'] = func(res['text'])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6a86e",
   "metadata": {},
   "source": [
    "### Apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4e031b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_df.label.tolist()\n",
    "test_df = pd.DataFrame(test_df.text.apply(apply_preprocessing).to_list())\n",
    "test_df['label'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42356a45",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4c976e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, lstm_out, mask):\n",
    "        # lstm_out: (B, T, H)\n",
    "        # mask: (B, T, 1)\n",
    "\n",
    "        scores = self.attn(lstm_out).squeeze(-1)  # (B, T)\n",
    "        scores = scores.masked_fill(mask.squeeze(-1) == 0, -1e9)\n",
    "\n",
    "        attn_weights = F.softmax(scores, dim=1)  # (B, T)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context = torch.sum(lstm_out * attn_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "        return context, attn_weights\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_matrix, lstm_hidden=128, lstm_layers=1, num_classes=3, embed_proj_size=128):\n",
    "        super().__init__()\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), padding_idx=0, freeze=True)\n",
    "\n",
    "        self.embed_proj = nn.Sequential(\n",
    "            nn.Linear(embedding_matrix.size(1), embed_proj_size),\n",
    "            nn.LayerNorm(embed_proj_size),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_proj_size,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.attention = AttentionPooling(lstm_hidden * 2)\n",
    "\n",
    "        self.layernorm = nn.LayerNorm(lstm_hidden * 2 + 4)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden * 2 + 4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_ids, extra_feats):\n",
    "        # Embedding\n",
    "        x = self.embedding(text_ids)  # (B, T, E)\n",
    "\n",
    "        x = self.embed_proj(x)\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x)  # (B, T, 2H)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # Mask padding\n",
    "        mask = (text_ids != 0).unsqueeze(-1)  # (B, T, 1)\n",
    "\n",
    "        # Attention\n",
    "        context, attn_weights = self.attention(lstm_out, mask)\n",
    "\n",
    "        # Concatenate extra features\n",
    "        features = torch.cat([context, extra_feats], dim=1)\n",
    "\n",
    "        features = self.layernorm(features)\n",
    "\n",
    "        logits = self.mlp(features)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3d2b7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"../model/embedding.pt\", map_location=\"cpu\")\n",
    "\n",
    "embedding_matrix = ckpt[\"embedding\"]\n",
    "word2idx = ckpt[\"word2idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8d0ffa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_15308\\564782598.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), padding_idx=0, freeze=True)\n"
     ]
    }
   ],
   "source": [
    "LSTM_HIDDEN = 128\n",
    "LSTM_LAYERS = 1\n",
    "EMBED_PROJ_SIZE = 128\n",
    "\n",
    "model = Model(embedding_matrix, lstm_hidden=LSTM_HIDDEN, lstm_layers=LSTM_LAYERS, embed_proj_size=EMBED_PROJ_SIZE).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "89aa9e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../model/clf.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766bd22",
   "metadata": {},
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "239b5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, word2idx, max_len=128):\n",
    "        self.df = dataframe\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        patterns = [\n",
    "            r\"\\[[A-Z_]+\\]\",\n",
    "            r\"<\\/?[\\w_]+>\",\n",
    "            r\"\\w+\",\n",
    "            r\"[?!]{2,}\",\n",
    "            r\"\\.{3,}\",\n",
    "            r\"[^\\w\\s]\"\n",
    "        ]\n",
    "\n",
    "        combined = re.compile(\"|\".join(patterns), re.UNICODE)\n",
    "\n",
    "        return combined.findall(text)\n",
    "\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        tokens = self.tokenize(text)\n",
    "        ids = [self.word2idx.get(token, self.word2idx['<unk>']) for token in tokens]\n",
    "        ids = ids[:self.max_len]\n",
    "\n",
    "        return ids + [self.word2idx['<pad>']] * (self.max_len - len(ids))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index]\n",
    "\n",
    "        text_ids = torch.tensor(self.encode_text(row['text']))\n",
    "        extra_feats = torch.tensor([\n",
    "            row[\"ex_intensity\"],\n",
    "            row[\"emoji_score\"],\n",
    "            row[\"all_uppercase\"],\n",
    "            row[\"uppercase_ratio\"]]\n",
    "        , dtype=torch.float32)\n",
    "\n",
    "        return text_ids, extra_feats, torch.tensor(int(row['label']), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c9a3e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "test_dataset = SentimentDataset(test_df, word2idx, max_len=MAX_LEN)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fedf05",
   "metadata": {},
   "source": [
    "### Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "274943c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate(model, dataloader, criterion=criterion, device='cuda', threshold=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text_ids, extra_feats, labels in tqdm(dataloader, desc='Validating'):\n",
    "            text_ids = text_ids.to(device)\n",
    "            extra_feats = extra_feats.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(text_ids, extra_feats)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "            if threshold is None:\n",
    "                preds = torch.argmax(probs, dim=1).to('cpu').tolist()\n",
    "            else:\n",
    "                preds = []\n",
    "\n",
    "                for p in probs:\n",
    "                    prob_pos = p[0].item()\n",
    "                    prob_neu = p[1].item()\n",
    "                    prob_neg = p[2].item()\n",
    "\n",
    "                    if prob_pos >= threshold.get('pos', 1/3) and prob_pos >= prob_neg:\n",
    "                        preds.append(0)\n",
    "                    elif prob_neg >= threshold.get('neg', 1/3) and prob_neg > prob_pos:\n",
    "                        preds.append(2)\n",
    "                    else:\n",
    "                        preds.append(1)\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average=None, labels=[0,1,2])\n",
    "    recall = recall_score(all_labels, all_preds, average=None, labels=[0,1,2])\n",
    "\n",
    "    precision_pos, precision_neu, precision_neg = precision\n",
    "    recall_pos, recall_neu, recall_neg = recall\n",
    "\n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'acc': acc,\n",
    "        'precision_pos': precision_pos,\n",
    "        'precision_neg': precision_neg,\n",
    "        'precision_neu': precision_neu,\n",
    "        'recall_pos': recall_pos,\n",
    "        'recall_neg': recall_neg,\n",
    "        'recall_neu': recall_neu,\n",
    "        'f1_pos': f1_score(all_labels, all_preds, average=None, labels=[0])[0],\n",
    "        'f1_neg': f1_score(all_labels, all_preds, average=None, labels=[2])[0],\n",
    "        'f1_neu': f1_score(all_labels, all_preds, average=None, labels=[1])[0],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e652a",
   "metadata": {},
   "source": [
    "### Call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "46bcaa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 54/54 [00:01<00:00, 39.00it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluation = evaluate(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu', threshold={'pos': 0.4, 'neg': 0.31})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4750ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.7557825087397186,\n",
       " 'acc': 0.7013403263403264,\n",
       " 'precision_pos': np.float64(0.6935849056603773),\n",
       " 'precision_neg': np.float64(0.7043650793650794),\n",
       " 'precision_neu': np.float64(0.707916287534122),\n",
       " 'recall_pos': np.float64(0.8556797020484171),\n",
       " 'recall_neg': np.float64(0.7222787385554426),\n",
       " 'recall_neu': np.float64(0.5658181818181818),\n",
       " 'f1_pos': np.float64(0.7661525635681534),\n",
       " 'f1_neg': np.float64(0.7132094424912104),\n",
       " 'f1_neu': np.float64(0.6289409862570736)}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
